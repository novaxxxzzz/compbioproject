{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75ee1642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Epoch 1/200\n",
      "283/283 [==============================] - 1s 2ms/step - loss: 1.0034 - accuracy: 0.5416 - val_loss: 0.9986 - val_accuracy: 0.5463\n",
      "Epoch 2/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.9930 - accuracy: 0.5450 - val_loss: 0.9914 - val_accuracy: 0.5463\n",
      "Epoch 3/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.9839 - accuracy: 0.5450 - val_loss: 0.9842 - val_accuracy: 0.5463\n",
      "Epoch 4/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.9728 - accuracy: 0.5450 - val_loss: 0.9745 - val_accuracy: 0.5463\n",
      "Epoch 5/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.9589 - accuracy: 0.5449 - val_loss: 0.9594 - val_accuracy: 0.5463\n",
      "Epoch 6/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.9413 - accuracy: 0.5465 - val_loss: 0.9436 - val_accuracy: 0.5480\n",
      "Epoch 7/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.9218 - accuracy: 0.5533 - val_loss: 0.9275 - val_accuracy: 0.5466\n",
      "Epoch 8/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.9021 - accuracy: 0.5661 - val_loss: 0.9068 - val_accuracy: 0.5665\n",
      "Epoch 9/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.8828 - accuracy: 0.5833 - val_loss: 0.8897 - val_accuracy: 0.5872\n",
      "Epoch 10/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.8653 - accuracy: 0.5983 - val_loss: 0.8752 - val_accuracy: 0.6065\n",
      "Epoch 11/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.8504 - accuracy: 0.6094 - val_loss: 0.8643 - val_accuracy: 0.6111\n",
      "Epoch 12/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.8384 - accuracy: 0.6187 - val_loss: 0.8546 - val_accuracy: 0.6173\n",
      "Epoch 13/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.8290 - accuracy: 0.6266 - val_loss: 0.8492 - val_accuracy: 0.6216\n",
      "Epoch 14/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.8213 - accuracy: 0.6322 - val_loss: 0.8422 - val_accuracy: 0.6224\n",
      "Epoch 15/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.8155 - accuracy: 0.6356 - val_loss: 0.8405 - val_accuracy: 0.6276\n",
      "Epoch 16/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.8113 - accuracy: 0.6360 - val_loss: 0.8362 - val_accuracy: 0.6276\n",
      "Epoch 17/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.8076 - accuracy: 0.6389 - val_loss: 0.8338 - val_accuracy: 0.6264\n",
      "Epoch 18/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.8048 - accuracy: 0.6384 - val_loss: 0.8337 - val_accuracy: 0.6259\n",
      "Epoch 19/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.8029 - accuracy: 0.6423 - val_loss: 0.8315 - val_accuracy: 0.6287\n",
      "Epoch 20/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.8009 - accuracy: 0.6396 - val_loss: 0.8300 - val_accuracy: 0.6244\n",
      "Epoch 21/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.7997 - accuracy: 0.6428 - val_loss: 0.8305 - val_accuracy: 0.6239\n",
      "Epoch 22/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.7986 - accuracy: 0.6424 - val_loss: 0.8289 - val_accuracy: 0.6227\n",
      "Epoch 23/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.7977 - accuracy: 0.6439 - val_loss: 0.8293 - val_accuracy: 0.6259\n",
      "Epoch 24/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.7966 - accuracy: 0.6437 - val_loss: 0.8309 - val_accuracy: 0.6236\n",
      "Epoch 25/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.7960 - accuracy: 0.6440 - val_loss: 0.8288 - val_accuracy: 0.6230\n",
      "Epoch 26/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.7954 - accuracy: 0.6441 - val_loss: 0.8279 - val_accuracy: 0.6259\n",
      "Epoch 27/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.7948 - accuracy: 0.6448 - val_loss: 0.8288 - val_accuracy: 0.6267\n",
      "Epoch 28/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.7947 - accuracy: 0.6431 - val_loss: 0.8276 - val_accuracy: 0.6244\n",
      "Epoch 29/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.7939 - accuracy: 0.6451 - val_loss: 0.8288 - val_accuracy: 0.6247\n",
      "Epoch 30/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.7939 - accuracy: 0.6457 - val_loss: 0.8281 - val_accuracy: 0.6236\n",
      "Epoch 31/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.7931 - accuracy: 0.6455 - val_loss: 0.8277 - val_accuracy: 0.6267\n",
      "Epoch 32/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.7931 - accuracy: 0.6442 - val_loss: 0.8278 - val_accuracy: 0.6256\n",
      "Epoch 33/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.7927 - accuracy: 0.6450 - val_loss: 0.8295 - val_accuracy: 0.6270\n",
      "Epoch 34/200\n",
      "228/283 [=======================>......] - ETA: 0s - loss: 0.7915 - accuracy: 0.6465Restoring model weights from the end of the best epoch: 19.\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.7924 - accuracy: 0.6441 - val_loss: 0.8280 - val_accuracy: 0.6264\n",
      "Epoch 34: early stopping\n",
      "\n",
      "===== Final Evaluation =====\n",
      "566/566 [==============================] - 0s 798us/step\n",
      "\n",
      "Training Q3 Accuracy: 64.34%\n",
      "\n",
      "Matthews CC:\n",
      "C_h: 0.372\n",
      "C_e: 0.343\n",
      "C__: 0.387\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2214  334 2053]\n",
      " [ 629 1219 1788]\n",
      " [1102  551 8215]]\n",
      "110/110 [==============================] - 0s 2ms/step\n",
      "\n",
      "Test Q3 Accuracy: 62.87%\n",
      "\n",
      "Matthews CC:\n",
      "C_h: 0.324\n",
      "C_e: 0.289\n",
      "C__: 0.386\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 375   56  418]\n",
      " [ 181  213  354]\n",
      " [ 178  120 1625]]\n",
      "Best Validation Accuracy: 0.628693163394928\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Lambda, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import matthews_corrcoef, confusion_matrix\n",
    "\n",
    "# ================== Configuration ==================\n",
    "AMINO_ACIDS = ['A','R','N','D','C','Q','E','G','H','I','L','K','M','F','P','S','T','W','Y','V']\n",
    "SPACER_IDX = 20  # 21st unit for spacer/padding\n",
    "LABEL_MAP = {'h':0, 'e':1, '_':2}  # 3-class mapping as per paper\n",
    "\n",
    "# ================== Data Loading & Preprocessing ==================\n",
    "def parse_data(file_path):\n",
    "    sequences = []\n",
    "    current_seq = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith('#') or not line:\n",
    "                continue\n",
    "            if line in ('<>', '<end>'):\n",
    "                if current_seq:\n",
    "                    sequences.append(current_seq)\n",
    "                    current_seq = []\n",
    "                continue\n",
    "            parts = line.split()\n",
    "            if len(parts) == 2 and parts[1].lower() in LABEL_MAP:\n",
    "                current_seq.append((parts[0].upper(), parts[1].lower()))\n",
    "    return sequences\n",
    "\n",
    "def create_dataset(sequences):\n",
    "    X, y = [], []\n",
    "    for seq in sequences:\n",
    "        seq_len = len(seq)\n",
    "        for i in range(seq_len):\n",
    "            # Create 13-residue window (i-6 to i+6)\n",
    "            window = []\n",
    "            for j in range(i-6, i+7):\n",
    "                if j < 0 or j >= seq_len:\n",
    "                    window.append(SPACER_IDX)\n",
    "                else:\n",
    "                    aa = seq[j][0]\n",
    "                    window.append(AMINO_ACIDS.index(aa) if aa in AMINO_ACIDS else SPACER_IDX)\n",
    "            \n",
    "            # One-hot encode (13 positions × 21 units)\n",
    "            encoded = np.zeros((13, 21), dtype=np.float32)\n",
    "            for pos, idx in enumerate(window):\n",
    "                encoded[pos, idx] = 1.0\n",
    "            X.append(encoded.flatten())\n",
    "            \n",
    "            # Encode label\n",
    "            label = LABEL_MAP[seq[i][1]]\n",
    "            y.append(label)\n",
    "    \n",
    "    return np.array(X), tf.keras.utils.to_categorical(y, num_classes=3)\n",
    "\n",
    "# ================== Model Architecture ==================\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "        # Input: 273 units (13×21), Hidden: 40 units (paper specification)\n",
    "        Dense(40, activation='sigmoid', input_dim=273),\n",
    "        \n",
    "        # Output with temperature scaling (T=1/2 as in paper)\n",
    "        Dense(3, activation='linear'),\n",
    "        Lambda(lambda x: x / 2),  # Temperature parameter\n",
    "        Activation('softmax')\n",
    "    ])\n",
    "    \n",
    "    # Original optimizer: SGD with lr=0.1, no momentum\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=SGD(learning_rate=0.1, momentum=0.0),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# ================== Evaluation Metrics ==================\n",
    "def print_metrics(y_true, y_pred, name=\"Dataset\"):\n",
    "    labels = list(LABEL_MAP.keys())\n",
    "    y_true_labels = np.argmax(y_true, axis=1)\n",
    "    y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "    \n",
    "    # Q3 Accuracy\n",
    "    acc = np.mean(y_true_labels == y_pred_labels)\n",
    "    print(f\"\\n{name} Q3 Accuracy: {acc*100:.2f}%\")\n",
    "    \n",
    "    # Matthews Correlation Coefficients\n",
    "    print(\"\\nMatthews CC:\")\n",
    "    for i, label in enumerate(labels):\n",
    "        mcc = matthews_corrcoef(y_true_labels == i, y_pred_labels == i)\n",
    "        print(f\"C_{label}: {mcc:.3f}\")\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_true_labels, y_pred_labels))\n",
    "\n",
    "# ================== Main Execution ==================\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data\n",
    "    train_data = parse_data(\"protein-secondary-structure.train.txt\")\n",
    "    test_data = parse_data(\"protein-secondary-structure.test.txt\")\n",
    "    \n",
    "    # Create datasets\n",
    "    X_train, y_train = create_dataset(train_data)\n",
    "    X_test, y_test = create_dataset(test_data)\n",
    "    \n",
    "    # Verify input dimension matches paper (13×21=273)\n",
    "    assert X_train.shape[1] == 273, \"Invalid input dimension!\"\n",
    "    \n",
    "    # Initialize model\n",
    "    model = create_model()\n",
    "    \n",
    "    # Early stopping based on validation accuracy\n",
    "    early_stop = EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=15,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Train with paper's parameters (200 epochs, batch size 64)\n",
    "    print(\"Training model...\")\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=200,\n",
    "        batch_size=64,\n",
    "        validation_data=(X_test, y_test),\n",
    "        callbacks=[early_stop],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Final evaluation\n",
    "    print(\"\\n===== Final Evaluation =====\")\n",
    "    print_metrics(y_train, model.predict(X_train), \"Training\")\n",
    "    print_metrics(y_test, model.predict(X_test), \"Test\")\n",
    "    print(\"Best Validation Accuracy:\", max(history.history['val_accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae30e380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "283/283 [==============================] - 1s 2ms/step - loss: 1.0030 - accuracy: 0.5442 - val_loss: 0.9984 - val_accuracy: 0.5463\n",
      "Epoch 2/100\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.9948 - accuracy: 0.5450 - val_loss: 0.9921 - val_accuracy: 0.5463\n",
      "Epoch 3/100\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.9870 - accuracy: 0.5450 - val_loss: 0.9857 - val_accuracy: 0.5463\n",
      "Epoch 4/100\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.9773 - accuracy: 0.5450 - val_loss: 0.9771 - val_accuracy: 0.5463\n",
      "Epoch 5/100\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.9649 - accuracy: 0.5450 - val_loss: 0.9628 - val_accuracy: 0.5463\n",
      "Epoch 6/100\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.9484 - accuracy: 0.5452 - val_loss: 0.9474 - val_accuracy: 0.5472\n",
      "Epoch 7/100\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.9295 - accuracy: 0.5487 - val_loss: 0.9311 - val_accuracy: 0.5474\n",
      "Epoch 8/100\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.9097 - accuracy: 0.5579 - val_loss: 0.9099 - val_accuracy: 0.5628\n",
      "Epoch 9/100\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.8899 - accuracy: 0.5774 - val_loss: 0.8921 - val_accuracy: 0.5810\n",
      "Epoch 10/100\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.8717 - accuracy: 0.5939 - val_loss: 0.8769 - val_accuracy: 0.6034\n",
      "Epoch 11/100\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.8558 - accuracy: 0.6082 - val_loss: 0.8652 - val_accuracy: 0.6145\n",
      "Epoch 12/100\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.8430 - accuracy: 0.6192 - val_loss: 0.8550 - val_accuracy: 0.6179\n",
      "Epoch 13/100\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.8328 - accuracy: 0.6263 - val_loss: 0.8489 - val_accuracy: 0.6273\n",
      "Epoch 14/100\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.8244 - accuracy: 0.6321 - val_loss: 0.8416 - val_accuracy: 0.6207\n",
      "Epoch 15/100\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.8180 - accuracy: 0.6339 - val_loss: 0.8398 - val_accuracy: 0.6287\n",
      "Epoch 16/100\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.8133 - accuracy: 0.6353 - val_loss: 0.8354 - val_accuracy: 0.6287\n",
      "Epoch 17/100\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.8093 - accuracy: 0.6372 - val_loss: 0.8330 - val_accuracy: 0.6290\n",
      "Epoch 18/100\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.8061 - accuracy: 0.6386 - val_loss: 0.8329 - val_accuracy: 0.6295\n",
      "Epoch 19/100\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.8040 - accuracy: 0.6403 - val_loss: 0.8308 - val_accuracy: 0.6284\n",
      "Epoch 20/100\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.8018 - accuracy: 0.6396 - val_loss: 0.8294 - val_accuracy: 0.6278\n",
      "Epoch 21/100\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.8005 - accuracy: 0.6416 - val_loss: 0.8301 - val_accuracy: 0.6270\n",
      "Epoch 22/100\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.7992 - accuracy: 0.6430 - val_loss: 0.8285 - val_accuracy: 0.6278\n",
      "Epoch 23/100\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.7983 - accuracy: 0.6435 - val_loss: 0.8290 - val_accuracy: 0.6264\n",
      "Epoch 24/100\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.7971 - accuracy: 0.6444 - val_loss: 0.8306 - val_accuracy: 0.6230\n",
      "Epoch 25/100\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.7964 - accuracy: 0.6436 - val_loss: 0.8287 - val_accuracy: 0.6216\n",
      "Epoch 26/100\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.7957 - accuracy: 0.6435 - val_loss: 0.8279 - val_accuracy: 0.6295\n",
      "Epoch 27/100\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.7951 - accuracy: 0.6437 - val_loss: 0.8288 - val_accuracy: 0.6290\n",
      "Epoch 28/100\n",
      "229/283 [=======================>......] - ETA: 0s - loss: 0.7991 - accuracy: 0.6431Restoring model weights from the end of the best epoch: 18.\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.7950 - accuracy: 0.6447 - val_loss: 0.8276 - val_accuracy: 0.6250\n",
      "Epoch 28: early stopping\n",
      "110/110 [==============================] - 0s 751us/step\n",
      "Qian & Sejnowski (1988) Q3 Accuracy: 62.95%\n",
      "Epoch 1/100\n",
      "283/283 [==============================] - 1s 2ms/step - loss: 0.9430 - accuracy: 0.5585 - val_loss: 0.8976 - val_accuracy: 0.5872\n",
      "Epoch 2/100\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.8713 - accuracy: 0.6007 - val_loss: 0.8662 - val_accuracy: 0.5997\n",
      "Epoch 3/100\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.8391 - accuracy: 0.6182 - val_loss: 0.8512 - val_accuracy: 0.6142\n",
      "Epoch 4/100\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.8181 - accuracy: 0.6334 - val_loss: 0.8448 - val_accuracy: 0.6190\n",
      "Epoch 5/100\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.8027 - accuracy: 0.6442 - val_loss: 0.8373 - val_accuracy: 0.6236\n",
      "Epoch 6/100\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.7880 - accuracy: 0.6539 - val_loss: 0.8346 - val_accuracy: 0.6276\n",
      "Epoch 7/100\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.7749 - accuracy: 0.6625 - val_loss: 0.8369 - val_accuracy: 0.6239\n",
      "Epoch 8/100\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.7635 - accuracy: 0.6699 - val_loss: 0.8261 - val_accuracy: 0.6321\n",
      "Epoch 9/100\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.7518 - accuracy: 0.6764 - val_loss: 0.8212 - val_accuracy: 0.6338\n",
      "Epoch 10/100\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.7412 - accuracy: 0.6831 - val_loss: 0.8188 - val_accuracy: 0.6318\n",
      "Epoch 11/100\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.7303 - accuracy: 0.6878 - val_loss: 0.8170 - val_accuracy: 0.6352\n",
      "Epoch 12/100\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.7201 - accuracy: 0.6948 - val_loss: 0.8161 - val_accuracy: 0.6318\n",
      "Epoch 13/100\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.7111 - accuracy: 0.7020 - val_loss: 0.8234 - val_accuracy: 0.6287\n",
      "Epoch 14/100\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.7013 - accuracy: 0.7057 - val_loss: 0.8237 - val_accuracy: 0.6375\n",
      "Epoch 15/100\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.7097 - val_loss: 0.8242 - val_accuracy: 0.6284\n",
      "Epoch 16/100\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.6848 - accuracy: 0.7114 - val_loss: 0.8198 - val_accuracy: 0.6347\n",
      "Epoch 17/100\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.6760 - accuracy: 0.7173 - val_loss: 0.8235 - val_accuracy: 0.6381\n",
      "Epoch 18/100\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.6674 - accuracy: 0.7205 - val_loss: 0.8258 - val_accuracy: 0.6298\n",
      "Epoch 19/100\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.6597 - accuracy: 0.7239 - val_loss: 0.8223 - val_accuracy: 0.6389\n",
      "Epoch 20/100\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.6520 - accuracy: 0.7278 - val_loss: 0.8233 - val_accuracy: 0.6409\n",
      "Epoch 21/100\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.6440 - accuracy: 0.7305 - val_loss: 0.8343 - val_accuracy: 0.6415\n",
      "Epoch 22/100\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.6368 - accuracy: 0.7356 - val_loss: 0.8336 - val_accuracy: 0.6375\n",
      "Epoch 23/100\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.6289 - accuracy: 0.7392 - val_loss: 0.8366 - val_accuracy: 0.6361\n",
      "Epoch 24/100\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.6214 - accuracy: 0.7417 - val_loss: 0.8444 - val_accuracy: 0.6270\n",
      "Epoch 25/100\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.6142 - accuracy: 0.7496 - val_loss: 0.8443 - val_accuracy: 0.6338\n",
      "Epoch 26/100\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.6078 - accuracy: 0.7482 - val_loss: 0.8470 - val_accuracy: 0.6290\n",
      "Epoch 27/100\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.6000 - accuracy: 0.7547 - val_loss: 0.8522 - val_accuracy: 0.6338\n",
      "Epoch 28/100\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.5933 - accuracy: 0.7570 - val_loss: 0.8555 - val_accuracy: 0.6298\n",
      "Epoch 29/100\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.5871 - accuracy: 0.7612 - val_loss: 0.8704 - val_accuracy: 0.6321\n",
      "Epoch 30/100\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.5810 - accuracy: 0.7645 - val_loss: 0.8610 - val_accuracy: 0.6284\n",
      "Epoch 31/100\n",
      "230/283 [=======================>......] - ETA: 0s - loss: 0.5722 - accuracy: 0.7704Restoring model weights from the end of the best epoch: 21.\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.5748 - accuracy: 0.7682 - val_loss: 0.8705 - val_accuracy: 0.6313\n",
      "Epoch 31: early stopping\n",
      "110/110 [==============================] - 0s 761us/step\n",
      "Rost & Sander (1993) Q3 Accuracy: 64.15%\n",
      "\n",
      "Improvement: +1.19 percentage points\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Lambda, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import matthews_corrcoef, confusion_matrix\n",
    "\n",
    "# ================== Configuration ==================\n",
    "AMINO_ACIDS = list(\"ARNDCQEGHILKMFPSTWYV\")\n",
    "SPACER = 'X'\n",
    "LABEL_MAP = {'h':0, 'e':1, '_':2}\n",
    "\n",
    "#  ================== BLOSUM62 MATRIX ==================\n",
    "# standard 20×20 + spacer row\n",
    "BLOSUM62 = {\n",
    "    'A': [ 4, -1, -2, -2,  0, -1, -1,  0, -2, -1, -1, -1, -1, -2, -1,  1,  0, -3, -2,  0],\n",
    "    'R': [-1,  5,  0, -2, -3,  1,  0, -2,  0, -3, -2,  2, -1, -3, -2, -1, -1, -3, -2, -3],\n",
    "    'N': [-2,  0,  6,  1, -3,  0,  0,  0,  1, -3, -3,  0, -2, -3, -2,  1,  0, -4, -2, -3],\n",
    "    'D': [-2, -2,  1,  6, -3,  0,  2, -1, -1, -3, -4, -1, -3, -3, -1,  0, -1, -4, -3, -3],\n",
    "    'C': [ 0, -3, -3, -3,  9, -3, -4, -3, -3, -1, -1, -3, -1, -2, -3, -1, -1, -2, -2, -1],\n",
    "    'Q': [-1,  1,  0,  0, -3,  5,  2, -2,  0, -3, -2,  1,  0, -3, -1,  0, -1, -2, -1, -2],\n",
    "    'E': [-1,  0,  0,  2, -4,  2,  5, -2,  0, -3, -3,  1, -2, -3, -1,  0, -1, -3, -2, -2],\n",
    "    'G': [ 0, -2,  0, -1, -3, -2, -2,  6, -2, -4, -4, -2, -3, -3, -2,  0, -2, -2, -3, -3],\n",
    "    'H': [-2,  0,  1, -1, -3,  0,  0, -2,  8, -3, -3, -1, -2, -1, -2, -1, -2, -2,  2, -3],\n",
    "    'I': [-1, -3, -3, -3, -1, -3, -3, -4, -3,  4,  2, -3,  1,  0, -3, -2, -1, -3, -1,  3],\n",
    "    'L': [-1, -2, -3, -4, -1, -2, -3, -4, -3,  2,  4, -2,  2,  0, -3, -2, -1, -2, -1,  1],\n",
    "    'K': [-1,  2,  0, -1, -3,  1,  1, -2, -1, -3, -2,  5, -1, -3, -1,  0, -1, -3, -2, -2],\n",
    "    'M': [-1, -1, -2, -3, -1,  0, -2, -3, -2,  1,  2, -1,  5,  0, -2, -1, -1, -1, -1,  1],\n",
    "    'F': [-2, -3, -3, -3, -2, -3, -3, -3, -1,  0,  0, -3,  0,  6, -4, -2, -2,  1,  3, -1],\n",
    "    'P': [-1, -2, -2, -1, -3, -1, -1, -2, -2, -3, -3, -1, -2, -4,  7, -1, -1, -4, -3, -2],\n",
    "    'S': [ 1, -1,  1,  0, -1,  0,  0,  0, -1, -2, -2,  0, -1, -2, -1,  4,  1, -3, -2, -2],\n",
    "    'T': [ 0, -1,  0, -1, -1, -1, -1, -2, -2, -1, -1, -1, -1, -2, -1,  1,  5, -2, -2,  0],\n",
    "    'W': [-3, -3, -4, -4, -2, -2, -3, -2, -2, -3, -2, -3, -1,  1, -4, -3, -2, 11,  2, -3],\n",
    "    'Y': [-2, -2, -2, -3, -2, -1, -2, -3,  2, -1, -1, -2, -1,  3, -3, -2, -2,  2,  7, -1],\n",
    "    'V': [ 0, -3, -3, -3, -1, -2, -2, -3, -3,  3,  1, -2,  1, -1, -2, -2,  0, -3, -1,  4],\n",
    "    'X': [0]*20\n",
    "}\n",
    "\n",
    "# ================== Robust Data Parsing ==================\n",
    "def parse_data(path):\n",
    "    sequences = []\n",
    "    current = []\n",
    "    with open(path) as f:\n",
    "        for line in f:\n",
    "            L = line.strip()\n",
    "            if not L or L.startswith('#'):\n",
    "                continue\n",
    "            if L in ('<>','<end>'):\n",
    "                if current:\n",
    "                    sequences.append(current)\n",
    "                    current = []\n",
    "                continue\n",
    "            parts = L.split()\n",
    "            if len(parts)==2 and parts[1].lower() in LABEL_MAP:\n",
    "                aa, lab = parts\n",
    "                current.append((aa.upper(), lab.lower()))\n",
    "            # else: skip any malformed lines\n",
    "    # catch last\n",
    "    if current:\n",
    "        sequences.append(current)\n",
    "    return sequences\n",
    "\n",
    "# ================== Window & Encoding ==================\n",
    "def make_windows(seqs, use_profile=False):\n",
    "    X, y = [], []\n",
    "    w = 6\n",
    "    for seq in seqs:\n",
    "        L = len(seq)\n",
    "        for i in range(L):\n",
    "            feats = []\n",
    "            for j in range(i-w, i+w+1):\n",
    "                aa = seq[j][0] if 0 <= j < L else SPACER\n",
    "                if use_profile:\n",
    "                    feats.extend(BLOSUM62[aa])\n",
    "                else:\n",
    "                    onehot = [0]*21\n",
    "                    idx = AMINO_ACIDS.index(aa) if aa in AMINO_ACIDS else 20\n",
    "                    onehot[idx] = 1\n",
    "                    feats.extend(onehot)\n",
    "            X.append(feats)\n",
    "            y.append(LABEL_MAP[seq[i][1]])\n",
    "    X = np.array(X, dtype=np.float32)\n",
    "    y = tf.keras.utils.to_categorical(y, num_classes=3)\n",
    "    return X, y\n",
    "\n",
    "# ================== Model Definition ==================\n",
    "def make_model(input_dim):\n",
    "    m = Sequential([\n",
    "        Dense(40, activation='sigmoid', input_dim=input_dim),\n",
    "        Dense(3, activation='linear'),\n",
    "        Lambda(lambda x: x/2),\n",
    "        Activation('softmax')\n",
    "    ])\n",
    "    m.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=SGD(learning_rate=0.1),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return m\n",
    "\n",
    "# ================== Q3 Printer ==================\n",
    "def print_Q3(name, y_true, y_pred):\n",
    "    yt = np.argmax(y_true, axis=1)\n",
    "    yp = np.argmax(y_pred, axis=1)\n",
    "    acc = np.mean(yt == yp)\n",
    "    print(f\"{name} Q3 Accuracy: {acc*100:.2f}%\")\n",
    "    return acc\n",
    "\n",
    "# ================== Main ==================\n",
    "if __name__ == \"__main__\":\n",
    "    # 1) Load\n",
    "    train = parse_data(\"protein-secondary-structure.train.txt\")\n",
    "    test  = parse_data(\"protein-secondary-structure.test.txt\")\n",
    "\n",
    "    # 2) Baseline (Qian & Sejnowski 1988)\n",
    "    X1, y1 = make_windows(train, use_profile=False)\n",
    "    X1t, y1t = make_windows(test,  use_profile=False)\n",
    "    model1 = make_model(X1.shape[1])\n",
    "    es = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True, verbose=1)\n",
    "    model1.fit(X1, y1, epochs=100, batch_size=64,\n",
    "               validation_data=(X1t, y1t), callbacks=[es], verbose=1)\n",
    "    acc1 = print_Q3(\"Qian & Sejnowski (1988)\", y1t, model1.predict(X1t))\n",
    "\n",
    "    # 3) Rost & Sander (1993) with BLOSUM62 profiles\n",
    "    X2, y2   = make_windows(train, use_profile=True)\n",
    "    X2t, y2t = make_windows(test,  use_profile=True)\n",
    "    model2 = make_model(X2.shape[1])\n",
    "    model2.fit(X2, y2, epochs=100, batch_size=64,\n",
    "               validation_data=(X2t, y2t), callbacks=[es], verbose=1)\n",
    "    acc2 = print_Q3(\"Rost & Sander (1993)\", y2t, model2.predict(X2t))\n",
    "\n",
    "    print(f\"\\nImprovement: +{(acc2-acc1)*100:.2f} percentage points\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
