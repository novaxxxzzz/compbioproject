{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f28a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "Epoch 1/200\n",
      "283/283 [==============================] - 1s 2ms/step - loss: 1.0022 - accuracy: 0.5391 - val_loss: 0.9967 - val_accuracy: 0.5463\n",
      "Epoch 2/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.9904 - accuracy: 0.5450 - val_loss: 0.9903 - val_accuracy: 0.5463\n",
      "Epoch 3/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.9805 - accuracy: 0.5450 - val_loss: 0.9802 - val_accuracy: 0.5463\n",
      "Epoch 4/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.9683 - accuracy: 0.5450 - val_loss: 0.9686 - val_accuracy: 0.5463\n",
      "Epoch 5/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.9529 - accuracy: 0.5450 - val_loss: 0.9513 - val_accuracy: 0.5463\n",
      "Epoch 6/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.9339 - accuracy: 0.5456 - val_loss: 0.9337 - val_accuracy: 0.5480\n",
      "Epoch 7/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.9134 - accuracy: 0.5516 - val_loss: 0.9158 - val_accuracy: 0.5520\n",
      "Epoch 8/200\n",
      "283/283 [==============================] - 0s 2ms/step - loss: 0.8922 - accuracy: 0.5688 - val_loss: 0.8958 - val_accuracy: 0.5710\n",
      "Epoch 9/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.8725 - accuracy: 0.5898 - val_loss: 0.8798 - val_accuracy: 0.5895\n",
      "Epoch 10/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.8559 - accuracy: 0.6076 - val_loss: 0.8685 - val_accuracy: 0.5940\n",
      "Epoch 11/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.8424 - accuracy: 0.6178 - val_loss: 0.8563 - val_accuracy: 0.6119\n",
      "Epoch 12/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.8318 - accuracy: 0.6257 - val_loss: 0.8488 - val_accuracy: 0.6236\n",
      "Epoch 13/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.8236 - accuracy: 0.6324 - val_loss: 0.8437 - val_accuracy: 0.6276\n",
      "Epoch 14/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.8175 - accuracy: 0.6329 - val_loss: 0.8396 - val_accuracy: 0.6295\n",
      "Epoch 15/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.8125 - accuracy: 0.6358 - val_loss: 0.8364 - val_accuracy: 0.6247\n",
      "Epoch 16/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.8087 - accuracy: 0.6391 - val_loss: 0.8346 - val_accuracy: 0.6281\n",
      "Epoch 17/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.8059 - accuracy: 0.6382 - val_loss: 0.8328 - val_accuracy: 0.6301\n",
      "Epoch 18/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.8037 - accuracy: 0.6411 - val_loss: 0.8325 - val_accuracy: 0.6298\n",
      "Epoch 19/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.8018 - accuracy: 0.6416 - val_loss: 0.8314 - val_accuracy: 0.6330\n",
      "Epoch 20/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.8002 - accuracy: 0.6426 - val_loss: 0.8304 - val_accuracy: 0.6295\n",
      "Epoch 21/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.7991 - accuracy: 0.6439 - val_loss: 0.8295 - val_accuracy: 0.6267\n",
      "Epoch 22/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.7981 - accuracy: 0.6454 - val_loss: 0.8293 - val_accuracy: 0.6287\n",
      "Epoch 23/200\n",
      "283/283 [==============================] - 0s 2ms/step - loss: 0.7968 - accuracy: 0.6435 - val_loss: 0.8295 - val_accuracy: 0.6284\n",
      "Epoch 24/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.7960 - accuracy: 0.6434 - val_loss: 0.8284 - val_accuracy: 0.6273\n",
      "Epoch 25/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.7957 - accuracy: 0.6436 - val_loss: 0.8286 - val_accuracy: 0.6267\n",
      "Epoch 26/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.7949 - accuracy: 0.6432 - val_loss: 0.8322 - val_accuracy: 0.6290\n",
      "Epoch 27/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.7944 - accuracy: 0.6447 - val_loss: 0.8282 - val_accuracy: 0.6264\n",
      "Epoch 28/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.7938 - accuracy: 0.6450 - val_loss: 0.8279 - val_accuracy: 0.6270\n",
      "Epoch 29/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.7933 - accuracy: 0.6462 - val_loss: 0.8283 - val_accuracy: 0.6276\n",
      "Epoch 30/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.7931 - accuracy: 0.6437 - val_loss: 0.8280 - val_accuracy: 0.6270\n",
      "Epoch 31/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.7929 - accuracy: 0.6440 - val_loss: 0.8313 - val_accuracy: 0.6284\n",
      "Epoch 32/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.7927 - accuracy: 0.6458 - val_loss: 0.8279 - val_accuracy: 0.6278\n",
      "Epoch 33/200\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.7920 - accuracy: 0.6452 - val_loss: 0.8294 - val_accuracy: 0.6253\n",
      "Epoch 34/200\n",
      "275/283 [============================>.] - ETA: 0s - loss: 0.7930 - accuracy: 0.6447Restoring model weights from the end of the best epoch: 19.\n",
      "283/283 [==============================] - 0s 1ms/step - loss: 0.7922 - accuracy: 0.6451 - val_loss: 0.8278 - val_accuracy: 0.6298\n",
      "Epoch 34: early stopping\n",
      "\n",
      "===== Final Evaluation =====\n",
      "566/566 [==============================] - 0s 701us/step\n",
      "\n",
      "Training Q3 Accuracy: 64.36%\n",
      "\n",
      "Matthews CC:\n",
      "C_h: 0.375\n",
      "C_e: 0.350\n",
      "C__: 0.391\n",
      "\n",
      "Confusion Matrix:\n",
      "[[2262  378 1961]\n",
      " [ 632 1324 1680]\n",
      " [1159  643 8066]]\n",
      "110/110 [==============================] - 0s 824us/step\n",
      "\n",
      "Test Q3 Accuracy: 63.30%\n",
      "\n",
      "Matthews CC:\n",
      "C_h: 0.344\n",
      "C_e: 0.287\n",
      "C__: 0.399\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 394   67  388]\n",
      " [ 179  227  342]\n",
      " [ 179  137 1607]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Lambda, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import matthews_corrcoef, confusion_matrix\n",
    "\n",
    "# ================== Configuration ==================\n",
    "AMINO_ACIDS = ['A','R','N','D','C','Q','E','G','H','I','L','K','M','F','P','S','T','W','Y','V']\n",
    "SPACER_IDX = 20  # 21st unit for spacer/padding\n",
    "LABEL_MAP = {'h':0, 'e':1, '_':2}  # 3-class mapping as per paper\n",
    "\n",
    "# ================== Data Loading & Preprocessing ==================\n",
    "def parse_data(file_path):\n",
    "    sequences = []\n",
    "    current_seq = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith('#') or not line:\n",
    "                continue\n",
    "            if line in ('<>', '<end>'):\n",
    "                if current_seq:\n",
    "                    sequences.append(current_seq)\n",
    "                    current_seq = []\n",
    "                continue\n",
    "            parts = line.split()\n",
    "            if len(parts) == 2 and parts[1].lower() in LABEL_MAP:\n",
    "                current_seq.append((parts[0].upper(), parts[1].lower()))\n",
    "    return sequences\n",
    "\n",
    "def create_dataset(sequences):\n",
    "    X, y = [], []\n",
    "    for seq in sequences:\n",
    "        seq_len = len(seq)\n",
    "        for i in range(seq_len):\n",
    "            # Create 13-residue window (i-6 to i+6)\n",
    "            window = []\n",
    "            for j in range(i-6, i+7):\n",
    "                if j < 0 or j >= seq_len:\n",
    "                    window.append(SPACER_IDX)\n",
    "                else:\n",
    "                    aa = seq[j][0]\n",
    "                    window.append(AMINO_ACIDS.index(aa) if aa in AMINO_ACIDS else SPACER_IDX)\n",
    "            \n",
    "            # One-hot encode (13 positions × 21 units)\n",
    "            encoded = np.zeros((13, 21), dtype=np.float32)\n",
    "            for pos, idx in enumerate(window):\n",
    "                encoded[pos, idx] = 1.0\n",
    "            X.append(encoded.flatten())\n",
    "            \n",
    "            # Encode label\n",
    "            label = LABEL_MAP[seq[i][1]]\n",
    "            y.append(label)\n",
    "    \n",
    "    return np.array(X), tf.keras.utils.to_categorical(y, num_classes=3)\n",
    "\n",
    "# ================== Model Architecture ==================\n",
    "def create_model():\n",
    "    model = Sequential([\n",
    "        # Input: 273 units (13×21), Hidden: 40 units (paper specification)\n",
    "        Dense(40, activation='sigmoid', input_dim=273),\n",
    "        \n",
    "        # Output with temperature scaling (T=1/2 as in paper)\n",
    "        Dense(3, activation='linear'),\n",
    "        Lambda(lambda x: x / 2),  # Temperature parameter\n",
    "        Activation('softmax')\n",
    "    ])\n",
    "    \n",
    "    # Original optimizer: SGD with lr=0.1, no momentum\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=SGD(learning_rate=0.1, momentum=0.0),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# ================== Evaluation Metrics ==================\n",
    "def print_metrics(y_true, y_pred, name=\"Dataset\"):\n",
    "    labels = list(LABEL_MAP.keys())\n",
    "    y_true_labels = np.argmax(y_true, axis=1)\n",
    "    y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "    \n",
    "    # Q3 Accuracy\n",
    "    acc = np.mean(y_true_labels == y_pred_labels)\n",
    "    print(f\"\\n{name} Q3 Accuracy: {acc*100:.2f}%\")\n",
    "    \n",
    "    # Matthews Correlation Coefficients\n",
    "    print(\"\\nMatthews CC:\")\n",
    "    for i, label in enumerate(labels):\n",
    "        mcc = matthews_corrcoef(y_true_labels == i, y_pred_labels == i)\n",
    "        print(f\"C_{label}: {mcc:.3f}\")\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_true_labels, y_pred_labels))\n",
    "\n",
    "# ================== Main Execution ==================\n",
    "if __name__ == \"__main__\":\n",
    "    # Load data\n",
    "    train_data = parse_data(\"protein-secondary-structure.train.txt\")\n",
    "    test_data = parse_data(\"protein-secondary-structure.test.txt\")\n",
    "    \n",
    "    # Create datasets\n",
    "    X_train, y_train = create_dataset(train_data)\n",
    "    X_test, y_test = create_dataset(test_data)\n",
    "    \n",
    "    # Verify input dimension matches paper (13×21=273)\n",
    "    assert X_train.shape[1] == 273, \"Invalid input dimension!\"\n",
    "    \n",
    "    # Initialize model\n",
    "    model = create_model()\n",
    "    \n",
    "    # Early stopping based on validation accuracy\n",
    "    early_stop = EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=15,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Train with paper's parameters (200 epochs, batch size 64)\n",
    "    print(\"Training model...\")\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=200,\n",
    "        batch_size=64,\n",
    "        validation_data=(X_test, y_test),\n",
    "        callbacks=[early_stop],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Final evaluation\n",
    "    print(\"\\n===== Final Evaluation =====\")\n",
    "    print_metrics(y_train, model.predict(X_train), \"Training\")\n",
    "    print_metrics(y_test, model.predict(X_test), \"Test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
